{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2x69Begxmfyu"},"source":["# MNIST : le \"Hello World\" du machine learning \n","\n","La base de données MNIST (pour Modified National Institute of Technology ) est une base de données de chiffres écrits à la main, en noir et blanc. Elle contient 70 000 images de ces chiffres, généralement réparties en 60 000 données d'entrainement et 10 000 données de test. Ces images sont de taille 28*28 pixels. \n","\n","C'est le BA-ba du machine learning. Il est assez facile d'obtenir de bons scores avec des algorithmes simplistes, ce qui en fait un problème idéal pour commencer en machine learning et s'habituer au workflow. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"zYR-5k5HmIPZ","executionInfo":{"status":"ok","timestamp":1665484305131,"user_tz":-120,"elapsed":485,"user":{"displayName":"Youcef Sklab","userId":"10303623923716491614"}}},"source":["from keras.datasets import mnist \n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0PKPw9OFo8uG"},"source":["## Visualisation des données \n","\n","Le dataset se compose en 4 éléments : \n","\n","\n","```\n","train_images , train_labels, test_images, test_labels \n","```\n","\n","Ces 4 éléments sont essentiels : \n","- Pour entrainer notre modèle, nous avons besoin de données et de leurs annotations (les labels)\n","- Pour tester si notre modèle est compétent, nous avons besoin de données 'neuves', que le modèle n'a encore jamais rencontré. \n","\n","Une fois le dataset chargé, on peut jeter un coup d'oeil aux données. Pour ça, on peut visuer quelques éléments du jeu d'entrainement : \n","\n"]},{"cell_type":"code","metadata":{"id":"C0IHHl8zpHG0"},"source":["import matplotlib.pyplot as plt \n","plt.rcParams['figure.figsize'] = (9,9) # Make the figures a bit bigger\n","for i in range(9):\n","    plt.subplot(3,3,i+1)\n","    plt.imshow(train_images[i], cmap='gray', interpolation='none')\n","    plt.title(\"Class {}\".format(train_labels[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HrDULp0Dm0Zd"},"source":["## Exploration des données \n","\n","Il est toujours conseillé d'explorer un dataset avant de chercher à l'exploiter. Pour l'utiliser, il faut le comprendre. Attelons nous donc à comprendre ce qu'est exactement le dataset MNIST. \n","\n","### formes et formats \n","\n","Sous quel format nous sont fournis les données ? Quelle est la répartition des données dans le dataset ? Pour connaitre ces informations, nous pouvons explorer les différents éléments dont nous disposons. \n","\n","Pour connaitre le type de structure : \n","\n","\n","```\n","type(train_images)\n","```\n","\n","La forme des données : \n","\n","\n","```\n","\n","train_images.shape \n","len(train_images)\n","#fonctionne pour des listes, des tableaux numpy, etc... \n","\n","```\n","\n","\n","### Train & test \n","Il peut être intéressant de voir si les données sont bien réparties. On parle ici de vérifier que les données d'entrainement et de test sont bien uniforméments réparties, et ne comportent pas de biais qui viendraient fausser les résultats recherchés. \n","\n","On peut par exemple checker la répartition de chacun des chiffres dans les deux différents jeux de données (entrainement et test )\n","\n"]},{"cell_type":"code","metadata":{"id":"CzuH91JtmWwA"},"source":["print(\" Type of data structure for the images : {}\".format(type(train_images)))\n","print(\" Type of data structure for the labels : {}\".format(type(train_labels)))\n","\n","print(\" Shape of the train images encoded as numpy arrays :  {}\".format(train_images.shape))\n","print(\" Length of the associated labels : {}\".format(len(train_labels)))\n","\n","print(\" Shape of the test images encoded as numpy arrays :  {}\".format(test_images.shape))\n","print(\" Length of the associated labels : {}\".format(len(test_labels)))\n","\n","print(\" Shape of an image : {}\".format(train_images[0].shape))\n","print(\" Example image : \\n {}\".format(train_images[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zupRuHmpYYBK"},"source":["train_counts=[]\n","test_counts=[]\n","for i in range(0,10):\n","  train_counts.append(len([k for k in train_labels if k ==i]))\n","  test_counts.append(len([k for k in test_labels if k ==i ]))\n","\n","  \n","plt.rcParams['figure.figsize'] = (16,8) # Make the figures a bit bigger\n","fig,(ax1,ax2,) = plt.subplots(1,2)\n","\n","x = range(0,10)\n","ax1.bar(x,train_counts)\n","ax1.set_title(\"count of apparition for each digit in the training set \")\n","\n","\n","ax2.bar(x,test_counts)\n","ax2.set_title(\"count of apparition for each digit in the test set \")\n","\n","\n","\n","plt.show()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7KY8TpSYrOxU"},"source":["## Preformattage : préparer les données \n","\n","Les données sont bien réparties, on peut maintenant les préparer à rentrer dans notre modèle ! \n","Une image est pour le moment un numpy array de taille 28*28. Ces array contiennent des valeurs de 0 à 255. Ce format est pratique pour l'affichage, mais pas pour le traitement de données : on préfère toujours se ramener à des valeurs entre 0 et 1. On va donc procéder à une remise à l'échelle. \n","\n","Le format des données peut aussi être simplifié : au lieu de posséder une matrice d'information pour une image, on peut en faire un array simple, de longueur 28*28. \n","\n"]},{"cell_type":"code","metadata":{"id":"80SensaVpLs_","executionInfo":{"status":"ok","timestamp":1665484307339,"user_tz":-120,"elapsed":2,"user":{"displayName":"Youcef Sklab","userId":"10303623923716491614"}}},"source":["train_images = train_images.reshape((60000,28*28))\n","train_images = train_images.astype('float32') / 255 \n","\n","test_images = test_images.reshape((10000,28*28))\n","test_images = test_images.astype('float32')/255\n","\n"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OCOs-eONsB6M"},"source":["Quel format utiliser pour les labels ? \n","\n","Notre souhait est de mettre au point un modèle capable de classifier une image dans une des 10 classes disponibles: les 10 chiffres de l'alphabet numérique. \n","Pour celà, le plus pratique est d'utiliser des bins : une représentation dans un tableau binaire de l'appartenance d'une donnée à une classe. Dit simplement : nous utilisons un tableau tel que tableau[i] vaut 1 si la donnée associée au tableau est i, et 0 sinon.  \n","\n","L'appartenance d'une image à la classe 5 se traduirait par le label suivant : [0,0,0,0,0,1,0,0,0,0]\n","\n","Il existe une fonction dans keras qui permet de faire cette transformation : \n","\n","```\n","to_categorical\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"4Z4VNz1UsDg_","executionInfo":{"status":"ok","timestamp":1665484307717,"user_tz":-120,"elapsed":380,"user":{"displayName":"Youcef Sklab","userId":"10303623923716491614"}}},"source":["#from keras.utils import to_categorical \n","from tensorflow.keras.utils import to_categorical\n","train_labels = to_categorical(train_labels) \n","test_labels = to_categorical(test_labels)\n","\n"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7GO4BE48sqnU"},"source":["# Un modèle, mon royaume pour un modèle ! \n","\n","## Comment c'est qu'on fait un modèle ? \n","\n","Rappel : un modèle, c'est ... \n","\n","![worfklow](https://docs.google.com/uc?export=download&id=17yxjq1_1kiddBFzeFIqyEB_mk68X3fq4)\n","\n","En entrée : des datas - ici, des images de taille 28*28\n","\n","En sortie : des labels - du même format que ceux utilisés pour l'entrainement. \n","\n","En sortie, il devra nous fournir un tableau de longueur 10 et comportant des valeurs entre 0 et 1, qui seront les probabilités que la donnée en entrée soit dans la classe appropriée ! \n","\n","Mais ce n'est pas tout : \n","- Un réseau de neurones comporte un certain nombre de ces neurones, et c'est à nous de décider combien ! \n","- C'est aussi ici que l'on décide du nombre de couches intermédiaires entre la couche d'entrée et de sortie : 100, 10, 1, 0 ? \n","- N'oublions pas les fonctions d'activation de ces neurones : quelle est la fonction non linéaire que nous allons appliquer en sortie des combinaisons linéaires des poids et inputs ? \n","\n","Voyons un premier exemple ci-dessous :\n"]},{"cell_type":"code","metadata":{"id":"Ln-OOSB8sN9_","executionInfo":{"status":"ok","timestamp":1665484310046,"user_tz":-120,"elapsed":2332,"user":{"displayName":"Youcef Sklab","userId":"10303623923716491614"}}},"source":["from keras import models \n","from keras import layers \n","\n","network = models.Sequential()\n","network.add(layers.Dense(32,activation = 'relu', input_shape = (28*28,)))\n","network.add(layers.Dense(10,activation='softmax'))"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qEa--h47ux8-"},"source":["\n","Faisons un peu de lecture du modèle ci-dessus : \n","\n","\n","\n","```\n","network = models.Sequential()\n","```\n","Cette ligne déclare que la variable network est un modèle qui pourra accueillir des couches. \n","\n","\n","\n","\n","```\n","network.add(layers.Dense(32,activation = 'relu', input_shape = (28*28,)))\n","```\n","\n","\n","C'est notre premier ajout de couches ! Il y a quatres éléments à retenir ici :\n","- le type de couche que nous utilisons est une couche Dense (layers.Dense). C'est la couche la plus simple : tous les neurones de la couche seront connectés à tous les neurones de la couche suivante ! \n","![dense network](https://docs.google.com/uc?export=download&id=1k8sInTooI-qTVfo8eoTbV4LRKv4kuRuL)\n","\n","\n","- Le nombre de neurones : pour cette première couche, nous avons décidé d'ne utiliser 32. Pourquoi 32 ? Eh bien, il n'y a pas vraiment de raison particulière, il s'agit d'un compromis ! On utilise généralement des puissances de 2 pour des raisons matérielles (question d'optimisation d'accès mémoire). Ensuite, plus on ajoute de neurones, plus notre modèle sera lourd, plus il sera computationnellement lent de l'entrainer ! A l'inverse, en mettre trop peu nous amènerait à avoir un modèle trop peu capable ...  C'est ici l'expérience qui nous fait désigner le réseau de la sorte ! \n","\n","- l'activation : nous avons utilisé la fonction 'relu' pour l'activation. Mais qu'est-ce qu'un 'relu' ? RELU veut dire REctified Linear Unit, cette fonction correspond à la fonction unité sur la tranche positive des réels et à la fonction nulle sur la tranche négative des réels. \n","![RELU](https://docs.google.com/uc?export=download&id=1wA90EN0WlZD6z16_YRaQqaTeUmSgtyB3)\n","\n","- La forme de l'input ! Il faut renseigner la forme des données qui vont être envoyées dans le réseau. Ici, 28*28 correspond à la taille d'une de nos données. \n","\n","Passons à la ligne suivante. \n","\n","\n","\n","```\n","network.add(layers.Dense(10,activation='softmax'))\n","```\n","\n","Ceci est notre dernière couche, la couche de sortie. Elle est composée : \n","\n","- du type de couche. Nous utilisons encore une couche Dense ici.\n","- du nombre de neurones. Ne nombre revêt un intérêt particulier, puisqu'il définit la taille de l'output. Puisque nous souhaitons un tableau à 10 valeurs. C'est donc 10 neurones dont nous aurons besoin. \n","- de l'activation. Nous souhaitons obtenir des valeurs entre 0 et 1. Ici, l'activation RELU n'est plus suffisante : elle peut produire des valeurs au dessus de 1 ... On utilise donc une autre activation, qui borne les valeurs dans l'intervalle (0,1)\n","\n","![Softmax](https://docs.google.com/uc?export=download&id=1xDReDAU1jWoDc_eCV7HAXZcm0XPnKOA6)\n","\n","Pas de couches intermédiaires, nous gardons le réseau le plus simple possible pour limiter les complications. \n","\n","Et voilà, le réseau est prêt à être utilisé ! \n","\n","On peut faire une visualisation de ce dernier avec la commande `summary`"]},{"cell_type":"code","metadata":{"id":"CDPenic0LwXo"},"source":["network.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"58Fusyf-u6VY"},"source":["## A quel point le modèle est-il mauvais ? \n","\n","Rappelons-nous le workflow de l'entrainement : \n","\n","\n","![Softmax](https://docs.google.com/uc?export=download&id=19Ma0VMeHUJQiwhJcHi5ElR-VJffWg2Rs)\n","\n","Il nous reste pour entrainer notre modèle à définir : \n","\n","- La loss function, ou fonction de perte : la fonction qui va nous permettre de définir une distance entre deux labels : le label prédit et le label attendu. Pour des labels sous la forme 'categorical' tels qu'on a actuellement, nous utiliserons une fonction qui est déjà dans keras : 'categorical_crossentropy'\n","\n","- Il existe plusieurs optimizers qui permettent de remonter l'information dans les poids (ou de parcourir l'espace des solutions et de rechercher un minimum global dans cet espace). Pour cet exemple, nous utiliserons 'rmsprop', qui sera explécité une autre fois. \n","\n","- Enfin, on peut rajouter des métriques que l'on peut suivre durant l'entrainement pour s'informer de son bon déroulement - la précision, par exemple.  "]},{"cell_type":"code","metadata":{"id":"2S-zQ5wTuOAe","executionInfo":{"status":"ok","timestamp":1665484310640,"user_tz":-120,"elapsed":11,"user":{"displayName":"Youcef Sklab","userId":"10303623923716491614"}}},"source":["network.compile(optimizer='rmsprop',\n","                loss = 'categorical_crossentropy',\n","                metrics =['accuracy'])\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5mBn7KnkvouU"},"source":["## S'entrainer pour mieux régner \n","\n","Tout est prêt ! Nous allons pouvoir entrainer notre modèle. \n","\n","Le principe de l'entrainement est le suivant : un ensemble de données (qu'on appelle un batch) est présenté au modèle. Ces données subissent les transformations inhérentes à leur passage dans les couches du modèle, jusqu'à l'output. Ensuite, de ces outputs, on calcule le loss score, qui correspond à la distance des labels prédits de l'ensemble du batch aux labels attendus de ce dernier. \n","\n","L'optimizer modifie alors les poids en fonction de ce loss score, et un nouveau batch est présenté au modèle pour répéter cette opération. \n","\n","Une fois l'ensemble des données présentées au modèle, on peut procéder à une phase de test de celui-ci. \n","\n","Mais pour que l'entrainement soit efficace, on peut répéter ces opérations ! Et donc, présenter plusieurs fois au modèle l'ensemble des données. On appellera la présentation de l'ensemble des données au modèle une epoch. On peut programmer plusieurs epochs et observer si présenter plusieurs fois le jeu de données au modèle améliore ses capacités ! "]},{"cell_type":"code","metadata":{"id":"fOX6j28DvePG"},"source":["epochs = 10\n","batch_size = 128\n","history = network.fit(train_images,train_labels,epochs=epochs,batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1NB54ZDawqCx"},"source":["Et voilà, le réseau est entrainé ! \n","\n","Qu'observe-t-on ? \n","- la loss affichée semble baisser au fur et à mesure des epochs \n","- l'accuracy (précision) semble elle augmenter, le réseau apprend ! \n","- à la dernière epoch, le réseau nous affiche une précision de 0.9850, soit 98,5% ! \n","\n","Mais ces données brutes sont assez peu exploitables. Commençons par essayer de nous représenter les avancées durant l'entrainement : nous avons gardé un historique des différentes étapes ! \n","\n","Cet historique est un dictionnaire contenant les scores de loss et d'acc durant les différentes étapes. On l'exploite comme ci-dessous pour en tirer des visualisations : "]},{"cell_type":"code","metadata":{"id":"4FpqYA9jwuj2"},"source":["history_dict = history.history \n","loss_values = history_dict['loss']\n","acc_values = history_dict['accuracy']\n","plt.rcParams['figure.figsize'] = (16,8) # Make the figures a bit bigger\n","fig,(ax1,ax2,) = plt.subplots(1,2)\n","\n","x = range(1,epochs+1)\n","ax1.plot(x,loss_values,'bo',label='Training Loss')\n","ax1.set_title('Training loss ')\n","ax1.set_xlabel('Epochs')\n","ax1.set_ylabel('Loss')\n","ax1.legend()\n","\n","\n","ax2.plot(x,acc_values,'bo',label='Training Accuracy')\n","ax2.set_title('Training accuracy ')\n","ax2.set_xlabel('Epochs')\n","ax2.set_ylabel('Accuracy')\n","ax2.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d6oaiJdKv8S3"},"source":["## Inférer pour tester\n","\n","L'inférence, c'est le fait d'utiliser le modèle pour en extraire de l'information.\n","\n","Il nous reste encore le test set, que nous n'avons pas encore présenté au modèle. Ce sont donc, pour le modèle, des nouvelles données auxquelles il n'a jamais été confronté. \n","\n","Nous possédons les labels associés aux données de ce set, mais nous n'allons pas les présenter au modèle - au contraire, nous ne lui fournissons que les données , et ce dernier infèrera les labels associés ! \n","\n","A nous de comparer ces labels prédits à ceux que nous possédons... \n","\n","Pas de panique, il existe une fonction pour ça ! Elle va calculer directement, sur le jeu de données test, la distance moyenne entre les labels prédits et ceux prévus, avec la fonction de perte que l'on a renseigné plus tôt ... "]},{"cell_type":"code","metadata":{"id":"x2wJYsPMv2Bn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665484355263,"user_tz":-120,"elapsed":2062,"user":{"displayName":"Youcef Sklab","userId":"10303623923716491614"}},"outputId":"541191cd-e87a-48fb-a94a-6849adf06275"},"source":["test_loss, test_acc = network.evaluate(test_images,test_labels)\n","print('accuracy on test set : {}'.format(test_acc))"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 2ms/step - loss: 0.1289 - accuracy: 0.9628\n","accuracy on test set : 0.9628000259399414\n"]}]},{"cell_type":"markdown","metadata":{"id":"i03evDQxwhKe"},"source":["Et voilà ! Notre réseau est déjà précis à plus de 96% ! \n","\n","Mais comment expliquer la différence entre la précision sur ce jeu de données et sur le jeu d'entrainement ? \n","En fait, il y a plusieurs variations : \n","- Ces jeux de données ne sont simplement pas les mêmes. On aura donc des différences possibles dans la réponse du modèle ... \n","- Le modèle a pu se 'sur-entrainer' sur le jeu de données. Qu'est-ce que ça veut dire ? Eh bien,on peut interprété ça comme le fait qu'il a triché pour gagner. Au lieu d'apprendre comment répondre à une question, le modèle a appris par coeur comment répondre à des questions en particulier, qui revenaient souvent ... sans comprendre ! Imaginez apprendre le principe de l'addition. Vous pouvez soit apprendre par coeur tous les résultats dans votre livre, ou apprendre à faire une addition grâce aux principes mathématiques de celle-ci. Devant une addition jamais vue auparavant, le second n'aura pas de mal, alors que le premier pourra ne pas répondre, ou répondre mal. Quand un modèle apprend 'trop bien', on dit qu'il fait de l'overfit : il s'est trop habitué à ses données d'entrainement et a plus appris à réagir à ses données d'entrainement qu'à apprendre les règles générales qui régissent ses données. Il existe plusieurs méthodes pour réduire ces effets, mais nous verrons ça plus tard ... "]},{"cell_type":"markdown","metadata":{"id":"ky18S7gFztNA"},"source":["# Et si je m'amusais un peu avec ce modèle ? \n","\n","\n","Ci-dessous : l'ensemble des paramètres du modèle ! \n","\n","Comment les modifier pour améliorer ce dernier ? \n","\n","A vous de jouer ! \n"]},{"cell_type":"code","metadata":{"id":"ODnP2EK9weap"},"source":["number_of_nodes =32\n","epochs = 10 \n","batch_size = 128\n","\n","network2 = models.Sequential()\n","network2.add(layers.Dense(number_of_nodes,activation = 'relu', input_shape = (28*28,)))\n","network2.add(layers.Dense(10,activation='softmax'))\n","\n","network2.compile(optimizer='rmsprop',\n","                loss = 'categorical_crossentropy',\n","                metrics =['accuracy'])\n","\n","history2 = network2.fit(train_images,train_labels,epochs=epochs,batch_size=batch_size)\n","\n","\n","history_dict = history2.history \n","loss_values = history_dict['loss']\n","acc_values = history_dict['accuracy']\n","plt.rcParams['figure.figsize'] = (16,8) # Make the figures a bit bigger\n","fig,(ax1,ax2,) = plt.subplots(1,2)\n","\n","x = range(1,epochs+1)\n","ax1.plot(x,loss_values,'bo',label='Training Loss')\n","ax1.set_title('Training loss ')\n","ax1.set_xlabel('Epochs')\n","ax1.set_ylabel('Loss')\n","ax1.legend()\n","\n","\n","ax2.plot(x,acc_values,'bo',label='Training Accuracy')\n","ax2.set_title('Training accuracy ')\n","ax2.set_xlabel('Epochs')\n","ax2.set_ylabel('Accuracy')\n","ax2.legend()\n","\n","plt.show()\n","\n","test_loss, test_acc = network2.evaluate(test_images,test_labels)\n","print('accuracy on test set : {}'.format(test_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_f3cD8l0pkj","executionInfo":{"status":"aborted","timestamp":1665484331616,"user_tz":-120,"elapsed":13,"user":{"displayName":"Youcef Sklab","userId":"10303623923716491614"}}},"source":[],"execution_count":null,"outputs":[]}]}